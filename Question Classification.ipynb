{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Brian is a doctor. He looks after sick people. He usually gets up at 6:00 o’clock. Today he is late, it is 6:30 and he is still in bed. He usually goes to work by train but today he is driving to work. He arrives at work at 6:30 every morning but it is 7:30 now and he is still driving. It’s 12:00 o’clock now. He always has his lunch at 12:00 but today he isn’t having lunch at 12:00, he is looking after his sick patients. It is half past seven now, Brian is watching TV. He usually watches TV at half past seven because his favorite programme starts at half past seven. Brian has his dinner at 8.30 everyday and he is having dinner now. It is 12:00 now Brian is going to bed. He always goes to bed at 12:00.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brian is a doctor. He looks after sick people. He usually gets up at 6:00 o’clock. Today he is late, it is 6:30 and he is still in bed. He usually goes to work by train but today he is driving to work. He arrives at work at 6:30 every morning but it is 7:30 now and he is still driving. It’s 12:00 o’clock now. He always has his lunch at 12:00 but today he isn’t having lunch at 12:00, he is looking after his sick patients. It is half past seven now, Brian is watching TV. He usually watches TV at half past seven because his favorite programme starts at half past seven. Brian has his dinner at 8.30 everyday and he is having dinner now. It is 12:00 now Brian is going to bed. He always goes to bed at 12:00.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Reference Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dict_cat0.pkl', 'rb') as file:  \n",
    "    dict_cat0 = pickle.load(file)\n",
    "    \n",
    "dict_cat0_inv = {v: k for k, v in dict_cat0.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dict_cat1.pkl', 'rb') as file:  \n",
    "    dict_cat1 = pickle.load(file)\n",
    "    \n",
    "dict_cat1_inv = {v: k for k, v in dict_cat1.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model1.pkl', 'rb') as file:  \n",
    "    model1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model2.pkl', 'rb') as file:  \n",
    "    model2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tfidf.pickle', 'rb') as file:  \n",
    "    vect = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qn = ['What does Brian do?',\n",
    "      'What time does he usually get up?',\n",
    "      'How does he usually go to work?',\n",
    "      'Why is he driving to work today?',\n",
    "      'What time does he arrive at work everyday?',\n",
    "      'When does he always have his lunch?',\n",
    "      'What is he doing at 12.00 today?',\n",
    "      'Why does he usually watch TV at 7.30?',\n",
    "      'What time is he going to bed now? ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qn Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ananthu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "qn_vector = vect.transform(qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cat0(qn_vector):\n",
    "\n",
    "    pred_model1, max_prob = [],[]\n",
    "    prob = model1.predict_proba(qn_vector)\n",
    "\n",
    "    for i in range(len(prob)):\n",
    "        max_prob.append(prob[i].max())\n",
    "        if prob[i].max() > 0.2:\n",
    "            pred_model1.append(dict_cat0_inv[prob[i].argmax()])\n",
    "        else:\n",
    "            pred_model1.append(np.nan)\n",
    "        \n",
    "    return pred_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cat1(qn_vector):\n",
    "\n",
    "    pred_model2, max_prob = [],[]\n",
    "    prob = model2.predict_proba(qn_vector)\n",
    "\n",
    "    for i in range(len(prob)):\n",
    "        max_prob.append(prob[i].max())\n",
    "        if prob[i].max() > 0.2:\n",
    "            pred_model2.append(dict_cat1_inv[prob[i].argmax()])\n",
    "        else:\n",
    "            pred_model2.append(np.nan)\n",
    "    \n",
    "    return pred_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What does Brian do?</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What time does he usually get up?</th>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How does he usually go to work?</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Why is he driving to work today?</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What time does he arrive at work everyday?</th>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Category1\n",
       "What does Brian do?                         DESCRIPTION\n",
       "What time does he usually get up?               NUMERIC\n",
       "How does he usually go to work?             DESCRIPTION\n",
       "Why is he driving to work today?            DESCRIPTION\n",
       "What time does he arrive at work everyday?      NUMERIC"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn_classify = pd.DataFrame(index = qn, data = {'Category1' : predict_cat0(qn_vector)}) #  'Category2' : pred_model2 })\n",
    "qn_classify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What does Brian do</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What time does he usually get up</th>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How does he usually go to work</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Why is he driving to work today</th>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What time does he arrive at work everyday</th>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Category1\n",
       "What does Brian do                         DESCRIPTION\n",
       "What time does he usually get up               NUMERIC\n",
       "How does he usually go to work             DESCRIPTION\n",
       "Why is he driving to work today            DESCRIPTION\n",
       "What time does he arrive at work everyday      NUMERIC"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn_classify_final = qn_classify.dropna()\n",
    "qn_classify_final.index = [x.split('?')[0] for x in list(qn_classify_final.index)] ### Remove '?' from index\n",
    "qn_classify_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brian</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6:00 o’clock</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6:30</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>today</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text Category\n",
       "0         Brian   PERSON\n",
       "1  6:00 o’clock     TIME\n",
       "2         Today     DATE\n",
       "3          6:30     TIME\n",
       "4         today     DATE"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame([(X.text, X.label_) for X in doc.ents])\n",
    "text_df.columns = ['Text', 'Category']\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_qn(qn): \n",
    "    \n",
    "    if type(qn) != list:\n",
    "        qn = [qn]\n",
    "    \n",
    "    qn_vector = vect.transform(qn)\n",
    "    \n",
    "    if predict_cat0(qn_vector)[0] == 'DESCRIPTION':\n",
    "        return 'sent'                                  ### Sentence\n",
    "\n",
    "    elif predict_cat0(qn_vector)[0] == 'LOCATION':\n",
    "        return 'location'                              ### Location\n",
    "\n",
    "    elif predict_cat0(qn_vector)[0] == 'NUMERIC':\n",
    "        return 'number'                                ### Cardinal, Date, Quantity, Time, Percent\n",
    "\n",
    "    elif predict_cat0(qn_vector)[0] == 'ENTITY':       \n",
    "        return 'entity'                                ### Sentence, Money \n",
    "\n",
    "    elif predict_cat0(qn_vector)[0] == 'HUMAN': \n",
    "        return 'human'                                 ### Sentence\n",
    "\n",
    "    elif predict_cat0(qn_vector)[0] == 'ABBREVIATION': \n",
    "        return 'abb'                                   ### Sentence\n",
    "\n",
    "    else:\n",
    "        return 'no answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qn1 = 'What time does he arrive at work everyday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ans(text, qn):\n",
    "    \n",
    "    similiar_sent,ent_list = [],[]\n",
    "    \n",
    "    sentence_list = text.split('.')[:-1]\n",
    "    \n",
    "    for sent in sentence_list:\n",
    "        similiar_sent.append(nlp(qn).similarity(nlp(sent)))\n",
    "        \n",
    "#     for vals in sentence_list:\n",
    "#         ent_list.append((X.text, X.label_) for X in nlp(vals).ents)\n",
    "        \n",
    "    similiar_index = sorted(range(len(similiar_sent)), key=lambda i: similiar_sent[i])[-3:]\n",
    "    \n",
    "    pred_class = classify_qn(qn)\n",
    "    print(pred_class)\n",
    "    \n",
    "    if similiar_sent[similiar_index[-1]] > 0.85 :\n",
    "    \n",
    "        if pred_class == 'sent':\n",
    "\n",
    "            if (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "\n",
    "        elif pred_class == 'location':\n",
    "\n",
    "            tup_list = [(X.text, X.label_) for X in nlp(sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]).ents]\n",
    "            d = list(dict(tup_list).values())\n",
    "            if d.count('GPE') == 1:\n",
    "                for vals in tup:\n",
    "                    if 'GPE' in vals:\n",
    "                        return vals[0]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "        elif pred_class == 'number':\n",
    "\n",
    "            tup_list = [(X.text, X.label_) for X in nlp(sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]).ents]\n",
    "            d = list(dict(tup_list).values())\n",
    "            if (d.count('GPE') == 1) or (:\n",
    "                for vals in tup:\n",
    "                    if 'GPE' in vals:\n",
    "                        return vals[0]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "            if (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "        elif pred_class == 'entity':\n",
    "\n",
    "            if (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "        elif pred_class == 'human':\n",
    "\n",
    "            if (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "        elif pred_class == 'abb':\n",
    "\n",
    "            if (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-3]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]] + sentence_list[similiar_index[-3]]\n",
    "\n",
    "            elif (similiar_sent[similiar_index[-1]] - similiar_sent[similiar_index[-2]]) < 0.0025:\n",
    "                return sentence_list[similiar_index[-1]] + sentence_list[similiar_index[-2]]\n",
    "\n",
    "            else:\n",
    "                return sentence_list[similiar_index[-1]]\n",
    "\n",
    "        else:\n",
    "            return \"Can't find any answer\"\n",
    "        \n",
    "    else:\n",
    "        return \"Can't find any answer\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text: \n",
      "'Brian is a doctor. He looks after sick people. He usually gets up at 6:00 o’clock. Today he is late, it is 6:30 and he is still in bed. He usually goes to work by train but today he is driving to work. He arrives at work at 6:30 every morning but it is 7:30 now and he is still driving. It’s 12:00 o’clock now. He always has his lunch at 12:00 but today he isn’t having lunch at 12:00, he is looking after his sick patients. It is half past seven now, Brian is watching TV. He usually watches TV at half past seven because his favorite programme starts at half past seven. Brian has his dinner at 8.30 everyday and he is having dinner now. It is 12:00 now Brian is going to bed. He always goes to bed at 12:00.'\n"
     ]
    }
   ],
   "source": [
    "text = input('Enter Text: \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Question: \n",
      "What is another main form of precipitation besides drizzle, rain, snow, sleet and hail?\n"
     ]
    }
   ],
   "source": [
    "qn = input('Enter Question: \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ananthu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Can't find any answer\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans(text, qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What time does he usually get up?',\n",
       " 'Why is he driving to work today?',\n",
       " 'What is he doing at 12.00 today?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['What time does he usually get up?',\n",
    "'Why is he driving to work today?',\n",
    "'What is he doing at 12.00 today?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_list = text.split('.')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similiar_sent = []\n",
    "\n",
    "for sent in sentence_list:\n",
    "    similiar_sent.append(nlp(qn).similarity(nlp(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7182411446355524,\n",
       " 0.847077614129077,\n",
       " 0.7053331549259318,\n",
       " 0.8503270895241182,\n",
       " 0.9351232062193044,\n",
       " 0.8484975478225513,\n",
       " 0.547673488187769,\n",
       " 0.853333372162675,\n",
       " 0.8272913228247624,\n",
       " 0.8158085941996177,\n",
       " 0.6942150920886285,\n",
       " 0.8470700640919865,\n",
       " 0.8442778305482955,\n",
       " 0.819141879258513]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similiar_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ent_list = []\n",
    "for vals in sentence_list:\n",
    "    ent_list.append([(X.text, X.label_) for X in nlp(vals).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similiar_index = sorted(range(len(similiar_sent)), key=lambda i: similiar_sent[i])[-3:]\n",
    "similiar_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004282340687038477"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9320104632079628 - 0.9277281225209243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What time does he arrive at work everyday'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similiar_sent = []\n",
    "for sent in sentence_list:\n",
    "    similiar_sent.append(nlp(qn1).similarity(nlp(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>['When did Beyonce start becoming popular?', '...</td>\n",
       "      <td>['in the late 1990s', 'singing and dancing', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frédéric François Chopin (/ˈʃoʊpæn/; French pr...</td>\n",
       "      <td>[\"What was Frédéric's nationalities?\", 'In wha...</td>\n",
       "      <td>['Polish and French', 'Romantic era', 'solo pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The exact nature of relations between Tibet an...</td>\n",
       "      <td>['Who were Wang Jiawei and Nyima Gyaincain?']</td>\n",
       "      <td>['Mainland Chinese scholars']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The iPod is a line of portable media players a...</td>\n",
       "      <td>['Which company produces the iPod?', 'When was...</td>\n",
       "      <td>['Apple', 'October 23, 2001', 'three', 'portab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>['When did Beyonce start becoming popular?', '...</td>\n",
       "      <td>['in the late 1990s', 'singing and dancing', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Frédéric François Chopin (/ˈʃoʊpæn/; French pr...   \n",
       "2  The exact nature of relations between Tibet an...   \n",
       "3  The iPod is a line of portable media players a...   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                           Questions  \\\n",
       "0  ['When did Beyonce start becoming popular?', '...   \n",
       "1  [\"What was Frédéric's nationalities?\", 'In wha...   \n",
       "2      ['Who were Wang Jiawei and Nyima Gyaincain?']   \n",
       "3  ['Which company produces the iPod?', 'When was...   \n",
       "4  ['When did Beyonce start becoming popular?', '...   \n",
       "\n",
       "                                             Answers  \n",
       "0  ['in the late 1990s', 'singing and dancing', '...  \n",
       "1  ['Polish and French', 'Romantic era', 'solo pi...  \n",
       "2                      ['Mainland Chinese scholars']  \n",
       "3  ['Apple', 'October 23, 2001', 'three', 'portab...  \n",
       "4  ['in the late 1990s', 'singing and dancing', '...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_csv('QA Dataset.csv')\n",
    "del(qa_df['Unnamed: 0'])\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ananthu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(qa_df)):\n",
    "    qn = []\n",
    "    \n",
    "    for vals in qa_df.loc[i,'Questions']:\n",
    "        qn.append(classify_qn(vals))\n",
    "    \n",
    "    qa_df.loc[i,'Questions'] = qn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
